#!/usr/bin/env python3
"""
PiCamera2ã‚’ä½¿ç”¨ã—ãŸå†™çœŸæ’®å½±ã¨Gemini AIã«ã‚ˆã‚‹ç”»åƒåˆ†æã‚¹ã‚¯ãƒªãƒ—ãƒˆ
éŸ³å£°ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºæ©Ÿèƒ½ä»˜ã
"""

from typing import Optional, List, Tuple, Any
from picamera2 import Picamera2
from datetime import datetime
import time
import os
from pathlib import Path
import google.generativeai as genai
from dotenv import load_dotenv
from PIL import Image
import soundfile as sf
import warnings
import sounddevice as sd
import librosa
import numpy as np

# éŸ³å£°éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿ï¼ˆæ—©æœŸå®šç¾©ãŒå¿…è¦ï¼‰
RECORDING_SAMPLE_RATE = 48000  # éŒ²éŸ³æ™‚ã®ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰
TARGET_SAMPLE_RATE = 16000  # å‡¦ç†ç”¨ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆï¼ˆHzï¼‰

# ONNXRuntimeã®GPUè­¦å‘Šã‚’æŠ‘åˆ¶ï¼ˆãƒ©ã‚ºãƒ‘ã‚¤ã§ã¯GPUãŒåˆ©ç”¨ã§ããªã„ãŸã‚ï¼‰
os.environ["ORT_DISABLE_ALL_PROVIDERS"] = "0"
warnings.filterwarnings("ignore", category=UserWarning, module="onnxruntime")

# USBãƒã‚¤ã‚¯ã®ãƒã‚¤ãƒ†ã‚£ãƒ–ã‚µãƒ³ãƒ—ãƒ«ãƒ¬ãƒ¼ãƒˆè¨­å®š
sd.default.samplerate = RECORDING_SAMPLE_RATE
sd.default.channels = 1

# .envãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ç’°å¢ƒå¤‰æ•°ã‚’èª­ã¿è¾¼ã‚€
load_dotenv()

# Gemini APIã®è¨­å®š
genai.configure(api_key=os.getenv("GEMINI_API_KEY"))
model = genai.GenerativeModel("gemini-2.0-flash")

# ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªï¼ˆ16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°æ¸ˆã¿ï¼‰
VOICE_EXAMPLES_DIR = "./voice_examples_16k"
WAKE_THRESHOLD = 0.04  # æ¤œå‡ºé–¾å€¤ï¼ˆå°ã•ã„ã»ã©å³æ ¼ã€å¤§ãã„ã»ã©ç·©ã„ï¼‰
RECORDING_DURATION = 5  # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆéŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
REFERENCE_AUDIO_LENGTH = 2.5  # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã®çµ±ä¸€é•·ï¼ˆç§’ï¼‰
RAG_PROMPT_FILE = "./rag_prompt.txt"  # RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãƒ•ã‚¡ã‚¤ãƒ«
PHOTO_DIR = "./Past_Photo"  # å†™çœŸä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª

# éŸ³å£°æ¤œå‡ºãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
VAD_SILENCE_THRESHOLD = 0.01  # ç„¡éŸ³åˆ¤å®šã®é–¾å€¤ï¼ˆRMSï¼‰
VAD_SILENCE_DURATION = 1.5  # ã“ã®ç§’æ•°ç„¡éŸ³ãŒç¶šã„ãŸã‚‰åœæ­¢ï¼ˆç§’ï¼‰
VAD_MIN_DURATION = 0.5  # æœ€ä½éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
VAD_CHUNK_SIZE = 4800  # éŸ³å£°ãƒãƒ£ãƒ³ã‚¯ã‚µã‚¤ã‚ºï¼ˆã‚µãƒ³ãƒ—ãƒ«æ•°ã€ç´„0.1ç§’åˆ†ï¼‰


def take_photo(filename: Optional[str] = None) -> str:
    """ã‚«ãƒ¡ãƒ©ã§å†™çœŸã‚’æ’®å½±ã™ã‚‹
    
    Args:
        filename: ä¿å­˜ã™ã‚‹ãƒ•ã‚¡ã‚¤ãƒ«åï¼ˆçœç•¥æ™‚ã¯ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ä»˜ãï¼‰
    
    Returns:
        str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Raises:
        RuntimeError: ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã¾ãŸã¯æ’®å½±ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    try:
        # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
        os.makedirs(PHOTO_DIR, exist_ok=True)
        
        # ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–
        picam2 = Picamera2()
        
        # ã‚«ãƒ¡ãƒ©è¨­å®š
        camera_config = picam2.create_still_configuration()
        picam2.configure(camera_config)
        
        # ã‚«ãƒ¡ãƒ©ã®èµ·å‹•
        picam2.start()
        
        # ã‚«ãƒ¡ãƒ©ã®ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—ï¼ˆæ¨å¥¨ï¼‰
        time.sleep(2)
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã«ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’ä½¿ç”¨
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"photo_{timestamp}.jpg"
        
        # ãƒ•ãƒ«ãƒ‘ã‚¹ã‚’ä½œæˆ
        filepath = os.path.join(PHOTO_DIR, filename)
        
        # å†™çœŸã‚’æ’®å½±
        picam2.capture_file(filepath)
        print(f"å†™çœŸã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        
        # ã‚«ãƒ¡ãƒ©ã®åœæ­¢
        picam2.stop()
        picam2.close()
        
        return filepath
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: å†™çœŸã®æ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise RuntimeError(f"å†™çœŸã®æ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e


def load_rag_prompt() -> str:
    """RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€
    
    Returns:
        str: RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆï¼ˆå­˜åœ¨ã—ãªã„å ´åˆã¯ç©ºæ–‡å­—åˆ—ï¼‰
    """
    if os.path.exists(RAG_PROMPT_FILE):
        with open(RAG_PROMPT_FILE, 'r', encoding='utf-8') as f:
            rag_content = f.read().strip()
            if rag_content:
                print(f"RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸï¼ˆ{len(rag_content)}æ–‡å­—ï¼‰")
                return rag_content
    return ""


def analyze_photo_with_gemini(image_path: str, prompt: str = "ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚", use_rag: bool = True) -> str:
    """æ’®å½±ã—ãŸå†™çœŸã‚’Gemini AIã§åˆ†æã™ã‚‹
    
    Args:
        image_path: åˆ†æã™ã‚‹ç”»åƒã®ãƒ‘ã‚¹
        prompt: Geminiã«é€ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        use_rag: RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’ä½¿ç”¨ã™ã‚‹ã‹
    
    Returns:
        str: Geminiã‹ã‚‰ã®å¿œç­”ãƒ†ã‚­ã‚¹ãƒˆ
        
    Raises:
        FileNotFoundError: ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        RuntimeError: Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(image_path):
        raise FileNotFoundError(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    
    try:
        # ç”»åƒã‚’èª­ã¿è¾¼ã‚€
        image = Image.open(image_path)
        
        # RAGãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã‚€
        rag_prompt = ""
        if use_rag:
            rag_prompt = load_rag_prompt()
        
        # ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’æ§‹ç¯‰
        if rag_prompt:
            full_prompt = f"""{rag_prompt}

---

ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®è³ªå•: {prompt}"""
        else:
            full_prompt = prompt
        
        # Geminiã§åˆ†æ
        print(f"\nGemini AIã§ç”»åƒã‚’åˆ†æä¸­...")
        print(f"ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ: {prompt}")
        if rag_prompt:
            print(f"ï¼ˆRAGã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆ: {len(rag_prompt)}æ–‡å­—ï¼‰")
        
        response = model.generate_content([full_prompt, image])
        
        return response.text
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise RuntimeError(f"Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e


def take_photo_and_analyze(prompt: str = "ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚") -> Tuple[str, str]:
    """å†™çœŸã‚’æ’®å½±ã—ã¦Gemini AIã§åˆ†æã™ã‚‹
    
    Args:
        prompt: Geminiã«é€ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
        
    Returns:
        Tuple[str, str]: (å†™çœŸã®ãƒ‘ã‚¹, åˆ†æçµæœ)
    """
    print("=" * 50)
    print("å†™çœŸæ’®å½±ã¨AIåˆ†æã‚’é–‹å§‹ã—ã¾ã™")
    print("=" * 50)
    
    # å†™çœŸã‚’æ’®å½±
    photo_path = take_photo()
    
    # Geminiã§åˆ†æ
    result = analyze_photo_with_gemini(photo_path, prompt)
    
    # çµæœã‚’è¡¨ç¤º
    print("\n" + "=" * 50)
    print("Gemini AIã®åˆ†æçµæœ:")
    print("=" * 50)
    print(result)
    print("=" * 50)
    
    return photo_path, result


def record_voice_prompt(duration: float = RECORDING_DURATION, existing_stream: Optional[Any] = None, use_vad: bool = True) -> Optional[str]:
    """éŸ³å£°ã§ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’éŒ²éŸ³ã™ã‚‹ï¼ˆéŸ³å£°æ¤œå‡ºã§è‡ªå‹•åœæ­¢ï¼‰
    
    Args:
        duration: æœ€å¤§éŒ²éŸ³æ™‚é–“ï¼ˆç§’ï¼‰
        existing_stream: æ—¢å­˜ã®å…¥åŠ›ã‚¹ãƒˆãƒªãƒ¼ãƒ ï¼ˆNoneã®å ´åˆã¯æ–°è¦ä½œæˆï¼‰
        use_vad: éŸ³å£°æ¤œå‡ºã‚’ä½¿ç”¨ã™ã‚‹ã‹ï¼ˆTrue: ç„¡éŸ³ã§è‡ªå‹•åœæ­¢, False: å›ºå®šæ™‚é–“éŒ²éŸ³ï¼‰
    
    Returns:
        str: éŒ²éŸ³ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã€ã¾ãŸã¯Noneï¼ˆã‚¨ãƒ©ãƒ¼ã®å ´åˆï¼‰
        
    Raises:
        ValueError: durationãŒç„¡åŠ¹ãªå€¤ã®å ´åˆ
    """
    # å…¥åŠ›å€¤ã®æ¤œè¨¼
    if duration <= 0:
        raise ValueError(f"durationã¯æ­£ã®æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {duration}")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    filename = f"prompt_{timestamp}.wav"
    
    if use_vad:
        print(f"\néŸ³å£°ã‚’éŒ²éŸ³ã—ã¾ã™ï¼ˆæœ€å¤§{duration}ç§’ã€ç„¡éŸ³ã§è‡ªå‹•åœæ­¢ï¼‰...")
        print("è©±ã—å§‹ã‚ã¦ãã ã•ã„...")
        
        audio_data = []
        silent_samples = 0
        silence_samples_needed = int(VAD_SILENCE_DURATION * RECORDING_SAMPLE_RATE)
        min_samples = int(VAD_MIN_DURATION * RECORDING_SAMPLE_RATE)
        max_samples = int(duration * RECORDING_SAMPLE_RATE)
        
        if existing_stream is None:
            print("ã‚¨ãƒ©ãƒ¼: éŸ³å£°æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã§ã¯æ—¢å­˜ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ãŒå¿…è¦ã§ã™")
            return None
        
        started = False
        
        while len(audio_data) < max_samples:
            chunk, _ = existing_stream.read(VAD_CHUNK_SIZE)
            chunk_audio = chunk[:, 0]
            audio_data.extend(chunk_audio)
            
            # RMSï¼ˆéŸ³é‡ï¼‰ã‚’è¨ˆç®—
            rms = np.sqrt(np.mean(chunk_audio ** 2))
            
            # éŸ³å£°ãŒé–‹å§‹ã•ã‚ŒãŸã‹ãƒã‚§ãƒƒã‚¯
            if not started and rms > VAD_SILENCE_THRESHOLD:
                started = True
                print("ğŸ¤ éŒ²éŸ³ä¸­...", end='', flush=True)
            
            # ç„¡éŸ³åˆ¤å®šï¼ˆéŸ³å£°é–‹å§‹å¾Œã®ã¿ï¼‰
            if started:
                if rms < VAD_SILENCE_THRESHOLD:
                    silent_samples += len(chunk_audio)
                    # é€²æ—è¡¨ç¤º
                    progress = int((silent_samples / silence_samples_needed) * 10)
                    print(f"\rğŸ¤ éŒ²éŸ³ä¸­... {'.' * progress}{' ' * (10 - progress)}", end='', flush=True)
                else:
                    silent_samples = 0
                    print(f"\rğŸ¤ éŒ²éŸ³ä¸­...          ", end='', flush=True)
                
                # ç„¡éŸ³ãŒç¶šã„ãŸã‚‰åœæ­¢ï¼ˆæœ€ä½éŒ²éŸ³æ™‚é–“ã‚’è¶…ãˆã¦ã„ã‚‹å ´åˆï¼‰
                if silent_samples >= silence_samples_needed and len(audio_data) >= min_samples:
                    print(f"\râœ“ ç„¡éŸ³ã‚’æ¤œå‡ºã€éŒ²éŸ³çµ‚äº†ï¼ˆ{len(audio_data) / RECORDING_SAMPLE_RATE:.1f}ç§’ï¼‰")
                    break
        
        audio = np.array(audio_data)
    else:
        print(f"\n{duration}ç§’é–“ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’éŒ²éŸ³ã—ã¾ã™...")
        print("è©±ã—å§‹ã‚ã¦ãã ã•ã„...")
        
        if existing_stream is not None:
            # æ—¢å­˜ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‹ã‚‰èª­ã¿å–ã‚‹
            samples_needed = int(duration * RECORDING_SAMPLE_RATE)
            audio_data = []
            
            while len(audio_data) < samples_needed:
                chunk, _ = existing_stream.read(min(12000, samples_needed - len(audio_data)))
                audio_data.extend(chunk[:, 0])
            
            audio = np.array(audio_data[:samples_needed])
        else:
            # æ–°ã—ã„ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½œæˆ
            audio = sd.rec(int(duration * RECORDING_SAMPLE_RATE), 
                           samplerate=RECORDING_SAMPLE_RATE, 
                           channels=1, 
                           dtype='float32')
            sd.wait()
            audio = audio[:, 0]
    
    # 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
    audio_16k = librosa.resample(audio, 
                                  orig_sr=RECORDING_SAMPLE_RATE, 
                                  target_sr=TARGET_SAMPLE_RATE)
    
    # ä¿å­˜
    sf.write(filename, audio_16k, TARGET_SAMPLE_RATE)
    
    if not use_vad:
        print(f"éŒ²éŸ³å®Œäº†: {filename}")
    return filename


def speech_to_text_with_gemini(audio_path: str) -> str:
    """éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’Geminiã§ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã™ã‚‹
    
    Args:
        audio_path: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
    
    Returns:
        str: å¤‰æ›ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ
        
    Raises:
        FileNotFoundError: éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚‰ãªã„å ´åˆ
        RuntimeError: Gemini APIã®å‘¼ã³å‡ºã—ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
    if not os.path.exists(audio_path):
        raise FileNotFoundError(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {audio_path}")
    
    try:
        print("éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ä¸­...")
        
        # Gemini APIã§éŸ³å£°ã‚’å‡¦ç†
        audio_file = genai.upload_file(path=audio_path)
        response = model.generate_content([
            "ã“ã®éŸ³å£°ã‚’æ­£ç¢ºã«æ–‡å­—èµ·ã“ã—ã—ã¦ãã ã•ã„ã€‚ãƒ†ã‚­ã‚¹ãƒˆã®ã¿ã‚’è¿”ã—ã¦ãã ã•ã„ã€‚",
            audio_file
        ])
        
        text = response.text.strip()
        print(f"èªè­˜ã•ã‚ŒãŸãƒ†ã‚­ã‚¹ãƒˆ: {text}")
        
        # ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰ã—ãŸãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
        audio_file.delete()
        
        return text
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise RuntimeError(f"éŸ³å£°ã®ãƒ†ã‚­ã‚¹ãƒˆå¤‰æ›ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e


def take_photo_and_analyze_with_voice() -> None:
    """ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’å¾…æ©Ÿã—ã€éŸ³å£°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã§å†™çœŸã‚’æ’®å½±ãƒ»åˆ†æã™ã‚‹"""
    import lwake.features as features
    
    print("=" * 50)
    print("éŸ³å£°èªè­˜ãƒ¢ãƒ¼ãƒ‰ã‚’é–‹å§‹ã—ã¾ã™")
    print(f"ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’è¨€ã£ã¦ãã ã•ã„...")
    print("=" * 50)
    
    # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’èª­ã¿è¾¼ã‚€
    print("ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’èª­ã¿è¾¼ã¿ä¸­...")
    reference_features = []
    for i in range(1, 5):
        ref_path = f"{VOICE_EXAMPLES_DIR}/Sample{i}.wav"
        if os.path.exists(ref_path):
            feat = features.extract_embedding_features(path=ref_path)
            reference_features.append((f"Sample{i}.wav", feat))
            print(f"  {ref_path} èª­ã¿è¾¼ã¿å®Œäº†")
    
    if not reference_features:
        print("ã‚¨ãƒ©ãƒ¼: ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return
    
    print(f"\n{len(reference_features)}å€‹ã®ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹éŸ³å£°ã‚’èª­ã¿è¾¼ã¿ã¾ã—ãŸ")
    print(f"ãƒãƒƒãƒ•ã‚¡ã‚µã‚¤ã‚º: {REFERENCE_AUDIO_LENGTH + 0.5}ç§’")
    print(f"é–¾å€¤: {WAKE_THRESHOLD}")
    print("\nã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã™...")
    
    # éŒ²éŸ³ãƒ‘ãƒ©ãƒ¡ãƒ¼ã‚¿
    buffer_duration = REFERENCE_AUDIO_LENGTH + 0.5
    slide_duration = 0.25
    
    buffer_samples = int(buffer_duration * RECORDING_SAMPLE_RATE)
    slide_samples = int(slide_duration * RECORDING_SAMPLE_RATE)
    
    audio_buffer = np.zeros(buffer_samples, dtype=np.float32)
    
    try:
        with sd.InputStream(samplerate=RECORDING_SAMPLE_RATE, channels=1, dtype=np.float32) as stream:
            while True:
                # éŸ³å£°ã‚’èª­ã¿å–ã‚‹
                data, overflowed = stream.read(slide_samples)
                
                chunk = data[:, 0]
                
                # ãƒãƒƒãƒ•ã‚¡ã‚’æ›´æ–°
                audio_buffer = np.roll(audio_buffer, -len(chunk))
                audio_buffer[-len(chunk):] = chunk
                
                # 16kHzã«ãƒªã‚µãƒ³ãƒ—ãƒªãƒ³ã‚°
                audio_16k = librosa.resample(audio_buffer, 
                                             orig_sr=RECORDING_SAMPLE_RATE, 
                                             target_sr=TARGET_SAMPLE_RATE)
                
                # ç‰¹å¾´æŠ½å‡º
                try:
                    feat = features.extract_embedding_features(y=audio_16k, sample_rate=TARGET_SAMPLE_RATE)
                except Exception as e:
                    continue
                
                # ãƒªãƒ•ã‚¡ãƒ¬ãƒ³ã‚¹ã¨æ¯”è¼ƒ
                detected = False
                min_distance = float('inf')
                best_match = None
                
                for ref_name, ref_feat in reference_features:
                    distance = features.dtw_cosine_normalized_distance(feat, ref_feat)
                    
                    if distance < min_distance:
                        min_distance = distance
                        best_match = ref_name
                    
                    if distance < WAKE_THRESHOLD:
                        print(f"\nâœ“ ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰æ¤œå‡º! ({ref_name}, è·é›¢: {distance:.4f})")
                        detected = True
                        break
                
                # ãƒ‡ãƒãƒƒã‚°: æœ€å°è·é›¢ã‚’å®šæœŸçš„ã«è¡¨ç¤ºï¼ˆ10å›ã«1å›ï¼‰
                if not detected and np.random.random() < 0.1:
                    print(f"  [ãƒ‡ãƒãƒƒã‚°] æœ€å°è·é›¢: {min_distance:.4f} ({best_match})", end='\r')
                
                if detected:
                    # éŸ³å£°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’éŒ²éŸ³ï¼ˆæ—¢å­˜ã®ã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’ä½¿ç”¨ï¼‰
                    prompt_audio = record_voice_prompt(existing_stream=stream)
                    
                    # éŸ³å£°ã‚’ãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›
                    prompt_text = speech_to_text_with_gemini(prompt_audio)
                    
                    # å†™çœŸã‚’æ’®å½±
                    print("\nå†™çœŸã‚’æ’®å½±ã—ã¾ã™...")
                    photo_path = take_photo()
                    
                    # Geminiã§åˆ†æ
                    result = analyze_photo_with_gemini(photo_path, prompt_text)
                    
                    # çµæœã‚’è¡¨ç¤º
                    print("\n" + "=" * 50)
                    print("Gemini AIã®åˆ†æçµæœ:")
                    print("=" * 50)
                    print(result)
                    print("=" * 50)
                    
                    # éŒ²éŸ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‰Šé™¤
                    os.remove(prompt_audio)
                    
                    # ãƒãƒƒãƒ•ã‚¡ã‚’ã‚¯ãƒªã‚¢
                    audio_buffer = np.zeros(buffer_samples, dtype=np.float32)
                    
                    print(f"\nå†åº¦ã‚¦ã‚§ã‚¤ã‚¯ãƒ¯ãƒ¼ãƒ‰ã‚’è¨€ã£ã¦ãã ã•ã„...")
    
    except KeyboardInterrupt:
        print("\n\néŸ³å£°èªè­˜ã‚’çµ‚äº†ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"\nã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        import traceback
        traceback.print_exc()

def take_multiple_photos(count: int = 3, interval: float = 2) -> List[str]:
    """è¤‡æ•°æšã®å†™çœŸã‚’é€£ç¶šæ’®å½±ã™ã‚‹
    
    Args:
        count: æ’®å½±æšæ•°
        interval: æ’®å½±é–“éš”ï¼ˆç§’ï¼‰
    
    Returns:
        list: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹ã®ãƒªã‚¹ãƒˆ
        
    Raises:
        ValueError: countã¾ãŸã¯intervalãŒç„¡åŠ¹ãªå€¤ã®å ´åˆ
    """
    # å…¥åŠ›å€¤ã®æ¤œè¨¼
    if count <= 0:
        raise ValueError(f"countã¯æ­£ã®æ•´æ•°ã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {count}")
    if interval < 0:
        raise ValueError(f"intervalã¯0ä»¥ä¸Šã§ã‚ã‚‹å¿…è¦ãŒã‚ã‚Šã¾ã™: {interval}")
    
    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(PHOTO_DIR, exist_ok=True)
    
    photo_paths = []
    picam2 = Picamera2()
    
    try:
        camera_config = picam2.create_still_configuration()
        picam2.configure(camera_config)
        picam2.start()
        
        time.sleep(2)  # ã‚¦ã‚©ãƒ¼ãƒ ã‚¢ãƒƒãƒ—
        
        for i in range(count):
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"photo_{timestamp}_{i+1}.jpg"
            filepath = os.path.join(PHOTO_DIR, filename)
            picam2.capture_file(filepath)
            photo_paths.append(filepath)
            print(f"å†™çœŸ {i+1}/{count} ã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
            
            if i < count - 1:
                time.sleep(interval)
    finally:
        # ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºå®Ÿãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        picam2.stop()
        picam2.close()
    
    return photo_paths

def take_photo_with_metadata() -> str:
    """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§å†™çœŸã‚’æ’®å½±ã™ã‚‹
    
    Returns:
        str: ä¿å­˜ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«ã®ãƒ‘ã‚¹
        
    Raises:
        RuntimeError: ã‚«ãƒ¡ãƒ©ã®åˆæœŸåŒ–ã¾ãŸã¯æ’®å½±ã«å¤±æ•—ã—ãŸå ´åˆ
    """
    # ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’ä½œæˆ
    os.makedirs(PHOTO_DIR, exist_ok=True)
    
    picam2 = Picamera2()
    
    try:
        # ã‚ˆã‚Šè©³ç´°ãªè¨­å®š
        config = picam2.create_still_configuration(
            main={"size": (1920, 1080)},  # è§£åƒåº¦ã®æŒ‡å®š
            lores={"size": (640, 480)},    # ä½è§£åƒåº¦ãƒ—ãƒ¬ãƒ“ãƒ¥ãƒ¼
            display="lores"
        )
        picam2.configure(config)
        picam2.start()
        
        time.sleep(2)
        
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"photo_{timestamp}.jpg"
        filepath = os.path.join(PHOTO_DIR, filename)
        
        # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¦å†™çœŸã‚’æ’®å½±
        metadata = picam2.capture_metadata()
        picam2.capture_file(filepath)
        
        print(f"å†™çœŸã‚’ä¿å­˜ã—ã¾ã—ãŸ: {filepath}")
        print(f"ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿: {metadata}")
        
        return filepath
    except Exception as e:
        print(f"ã‚¨ãƒ©ãƒ¼: å†™çœŸã®æ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}")
        raise RuntimeError(f"å†™çœŸã®æ’®å½±ã«å¤±æ•—ã—ã¾ã—ãŸ: {e}") from e
    finally:
        # ãƒªã‚½ãƒ¼ã‚¹ã®ç¢ºå®Ÿãªã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        picam2.stop()
        picam2.close()

if __name__ == "__main__":
    # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§éŸ³å£°èªè­˜ãƒ¢ãƒ¼ãƒ‰
    take_photo_and_analyze_with_voice()
    
    # ä»¥ä¸‹ã¯ä½¿ç”¨ä¾‹ï¼ˆã‚³ãƒ¡ãƒ³ãƒˆã‚¢ã‚¦ãƒˆï¼‰
    # åŸºæœ¬çš„ãªä½¿ç”¨ä¾‹: å†™çœŸã‚’æ’®å½±ã—ã¦AIåˆ†æ
    # take_photo_and_analyze("ã“ã®ç”»åƒã«ã¤ã„ã¦è©³ã—ãèª¬æ˜ã—ã¦ãã ã•ã„ã€‚")
    
    # ã‚«ã‚¹ã‚¿ãƒ ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã®ä¾‹
    # take_photo_and_analyze("ã“ã®ç”»åƒã«å†™ã£ã¦ã„ã‚‹ã‚‚ã®ã‚’æ—¥æœ¬èªã§ãƒªã‚¹ãƒˆã‚¢ãƒƒãƒ—ã—ã¦ãã ã•ã„ã€‚")
    
    # å†™çœŸã®ã¿æ’®å½±ã™ã‚‹ä¾‹
    # photo_path = take_photo()
    
    # æ—¢å­˜ã®å†™çœŸã‚’åˆ†æã™ã‚‹ä¾‹
    # result = analyze_photo_with_gemini("existing_photo.jpg", "ã“ã®ç”»åƒã¯ä½•ã§ã™ã‹ï¼Ÿ")
    # print(result)
    
    # è¤‡æ•°æšæ’®å½±ã®ä¾‹
    # print("\n3æšã®å†™çœŸã‚’é€£ç¶šæ’®å½±ã—ã¾ã™...")
    # take_multiple_photos(count=3, interval=2)
    
    # ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãæ’®å½±ã®ä¾‹
    # print("\nãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ä»˜ãã§å†™çœŸã‚’æ’®å½±ã—ã¾ã™...")
    # take_photo_with_metadata()
