import os
from dotenv import load_dotenv
import google.generativeai as genai
from PIL import Image

load_dotenv()

# ãƒ—ãƒ­ã‚­ã‚·è¨­å®šï¼ˆç’°å¢ƒå¤‰æ•°ã‹ã‚‰èª­ã¿è¾¼ã¿ï¼‰
proxy_http = os.getenv('HTTP_PROXY') or os.getenv('http_proxy')
proxy_https = os.getenv('HTTPS_PROXY') or os.getenv('https_proxy')

#if proxy_http or proxy_https:
 #   print(f"ãƒ—ãƒ­ã‚­ã‚·ã‚’ä½¿ç”¨ã—ã¾ã™: HTTP={proxy_http}, HTTPS={proxy_https}")
  #  # ç’°å¢ƒå¤‰æ•°ãŒè¨­å®šã•ã‚Œã¦ã„ã‚Œã°ã€requestsãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè‡ªå‹•çš„ã«ä½¿ç”¨ã—ã¾ã™
   # os.environ['HTTP_PROXY'] = proxy_http or ''
    #os.environ['HTTPS_PROXY'] = proxy_https or ''

GOOGLE_API_KEY = os.getenv('GOOGLE_API_KEY')
genai.configure(api_key=GOOGLE_API_KEY)

# gemini-flash-lite-latest ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
gemini_model = genai.GenerativeModel("gemini-flash-lite-latest")

# gemini-flash-lite-latest ãƒ¢ãƒ‡ãƒ«ã‚’ä½¿ç”¨
gemini_model = genai.GenerativeModel("gemini-flash-lite-latest")

# ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã®è¨­å®š
default_image_path = r"C:\Users\finou\OneDrive\ç”»åƒ\Camera Roll\WIN_20251022_23_33_40_Pro.jpg"
image_path_input = input(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹ã‚’å…¥åŠ›ã—ã¦ãã ã•ã„ï¼ˆEnterã§ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆä½¿ç”¨ï¼‰: ")
image_path = image_path_input.strip() if image_path_input.strip() else default_image_path

print(f"ä½¿ç”¨ã™ã‚‹ç”»åƒ: {image_path}")

try:
    image = Image.open(image_path)
    print("ç”»åƒã®èª­ã¿è¾¼ã¿ãŒå®Œäº†ã—ã¾ã—ãŸã€‚")
except FileNotFoundError:
    print(f"ç”»åƒãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {image_path}")
    exit(1)
except Exception as e:
    print(f"ç”»åƒã®èª­ã¿è¾¼ã¿ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
    exit(1)

# prompt.txtã‹ã‚‰äº‹å‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã‚’èª­ã¿è¾¼ã¿
try:
    with open("prompt.txt", "r", encoding="utf-8") as f:
        base_prompt = f.read().strip()
    print("äº‹å‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:")
    print(base_prompt)
    print("\n" + "="*50 + "\n")
except FileNotFoundError:
    base_prompt = ""
    print("prompt.txtãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚äº‹å‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆãªã—ã§å®Ÿè¡Œã—ã¾ã™ã€‚")

# ãƒ¦ãƒ¼ã‚¶ãƒ¼ã‹ã‚‰ã®è¿½åŠ å…¥åŠ›ã‚’å—ã‘å–ã‚Š
user_input = input("è¿½åŠ ã®è³ªå•ã‚„æŒ‡ç¤ºã‚’å…¥åŠ›ã—ã¦ãã ã•ã„: ")

# äº‹å‰ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆã¨ãƒ¦ãƒ¼ã‚¶ãƒ¼å…¥åŠ›ã‚’çµåˆ
if base_prompt:
    full_prompt = base_prompt + user_input
else:
    full_prompt = user_input

print(f"\né€ä¿¡ã™ã‚‹ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ:\n{full_prompt}")
print("\n" + "="*50 + "\n")

# APIãƒªã‚¯ã‚¨ã‚¹ãƒˆå®Ÿè¡Œ
print("APIãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚’é€ä¿¡ä¸­...")
response = gemini_model.generate_content([full_prompt, image])
print(f"\nãƒ¢ãƒ‡ãƒ«: gemini-flash-lite-latest")
print("="*60)
print("ğŸ¤– AIã®å›ç­”:")
print("="*60)
print(f"{response.text}")
print("="*60)
